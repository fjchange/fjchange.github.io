---
layout:     post
title:      " ICCV 2019 | 记住正常来发现异常：记忆增强的自编码器以无监督异常检测"
subtitle:   "ICCV 2019| Memorizing Normality to Detect Anomaly: Memory-augmented DeepAutoencoder for Unsupervised Anomaly Detection"
date:       2019-07-25
author:     "kiwi"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - VAD
    - unsupervised
    - AE
---
# ICCV 2019 | 记住正常来发现异常：记忆增强的自编码器以无监督异常检测

[paper](https://arxiv.org/pdf/1904.02639.pdf) [project page](https://donggong1.github.io/anomdec-memae.html) [code](https://donggong1.github.io/anomdec-memae.html)

## 1. Overview

### 1.1 Motivation

自编码器在异常检测中广泛的使用（对此的总结回顾可参考[异常检测概述（二）：Reconstruction Model](https://zhuanlan.zhihu.com/p/60305685))，在半监督/无监督的设定下，AE是期望异常的重构损失是较大的，而正常则不然，那么就可以区分这两者，但是实际上并不能保证这一点，AE实际上会把部分的异常也较好的重构，大部分的文章都认为这是AE泛化能力过强。而本文针对此问题，对AE做了记忆增强（Memory Augmentated AE）的操作来尝试克服这个问题。

![](https://i.loli.net/2019/07/26/5d3aa30ab8a4674863.png)

### 1.2 Idea

传统的AE是通过Encoder产生隐特征向量Z，然后经过Decoder还原到图像空间。而MemAE实际上是做了对Z的限制（以往的做法是对Z分布做限制，或者是做一些正则），而这里是以少量有限的prototype来代替Z，训练时Z以最近邻匹配最近的prototype，那么Decoder的input就是最近邻的prototype，训练会同时优化prototype，使得正常样本重构能够得到较贴合的还原。测试时，异常样本会匹配到正常的prototype，那么其重构损失就会相当明显，由此来发现异常。

## 2. Model Design

![](https://i.loli.net/2019/07/26/5d3aa5ea5146390027.png)

### 2.1 Encoder & Decoder

Encoder就是通过对于输入x，模型参数为$\theta_e$ ，计算得到特征向量Z，而Z经过MemAE之后得到的是z^，那么Decoder就是通过$\theta_d$产生X^。传统AE就是Z^=Z。

![](https://i.loli.net/2019/07/26/5d3ac33aa372175661.png)

### 2.2 Memory Module

当然如果直接使用Z与prototype最近邻too hard，这里通过产生记忆矩阵M=$R^{N*C}$，其中N意味着memory slot个数，C是特征维度长度，Z是1*C,维，也就是通过N个prototype的加权求和来近似表示Z。

![](https://i.loli.net/2019/07/26/5d3ac4e617d5371293.png)

对于N这个超参，文中说并不是很重要，够大就好了。

![](https://i.loli.net/2019/07/26/5d3af9f11fb3012622.png)

距离是采用cosine距离，而这个w是通过softmax方法计算，这就美其名曰Attention..

![](https://i.loli.net/2019/07/26/5d3ac7586e8a474969.png)

#### 2.2.1 Hard Shrinkage

如果没有对W进行约束，通过prototype的组合还是有可能导致异常也能被重构，那么这里对W也进行了类似Relu的Hard Shrinkage约束，其实就是超过阈值才保留，不超过阈值就是0。

![](https://i.loli.net/2019/07/26/5d3ac8643867b16044.png)

为了能够让这能够算梯度，结合Relu做了一点调整。

![](https://i.loli.net/2019/07/26/5d3ac877572d335566.png)

这里的超参数$\lambda$是认为设定在[1/N,3/N]为宜。

### 2.3 Loss

这里包含了两个loss，一个就是常见的MSE，来期望重构好图像。另外一个就是对W的稀疏限制，也就是期望的W的熵越小越好。两者通过$\alpha$进行权重调节，一般设为0.0002

![](https://i.loli.net/2019/07/26/5d3ac968c429144082.png)

## 3. Experiments

### 3.1 on MINIST & Cifar10

实验在MINIST和Cifar10上，在一个类里面训练然后另外的类视作异常的方法进行测试，然后通过对比MSE得到anomaly score

![](https://i.loli.net/2019/07/26/5d3acad4949b760174.png)

以上看到的结果发现做了“记忆”的操作是能够使得异常检测能力提高，但是Cifar10上整体比较差，说是其类间有很多变量导致的。下图可以看出而单个slot的memory重构的结果，都是跟训练集是相关的。

![](https://i.loli.net/2019/07/26/5d3af2b95072c42312.png)

由此，对于未知的训练集，那么其更偏向于重构出已知的类别，这也就是说更能保证异常重构类似正常，从而区分开两者。

![](https://i.loli.net/2019/07/26/5d3af2cc0b55c45232.png)

### 3.2 VAD

在Ped2、ShanghaiTech、Avenue数据集上的结果：

![](https://i.loli.net/2019/07/26/5d3af3b1181fb23615.png)

其中异常分值是通过对重构帧的重构损失的帧内归一化，1-之即为正常分值：

![](https://i.loli.net/2019/07/26/5d3af46523fb312230.png)

![](https://i.loli.net/2019/07/26/5d3af482b736314459.png)

### 3.3 Cybersecurity Dataset 

对于未知物体来说，这样的重构误差会更为明显，如上图。那么对于贴近正常的异常，这恐怕无能为力，AE本身的异常发现能力相对有限，但是本文的目标并不是为了刷榜，这种方法在异常检测中可以推广，继续扩展，比如用在时序数据中，这里在网络安全的数据上做了测试：

![](https://i.loli.net/2019/07/26/5d3af53e6263045453.png)

其能力确实相对来说有很大提高，这或许是因为图像空间中，采用MSE做重构损失容易导致图像模糊，模糊的图像计算error的差距相对不明显？对于离散的数据来说，更能显现出这个方法的能力。

### 3.4 Ablation Study

在ped2上做的消融实验，对比AE和AE+l1_norm，相对于仅仅只是加了隐向量正则，有“记忆”的存在，让Z是有限prototype的加权组合来近似Z，相对于L1正则约束Z更加能够让模型保证异常发现能力。

![](https://i.loli.net/2019/07/26/5d3af882dfe7283058.png)

## 4. Discussion

这篇文章相对于以往的方法，提出了可靠的机制来保证重构的异常能够有更大的重构损失，diss了聚类的方法通常对于高维度的数据通常面临次最优的表现（现在的方法都是通过将图像空间做特征抽取后，再做聚类，维度已将大为下降，这里好像diss错地方了）

记住正常的prototype，以之重组正常，一定程度上保证未知的异常，尤其是未见过的物体的重构。

本文的实验都做的很简单，如果要提高性能，可以考虑视频的时序特性，帧间变化，应该有更有趣的拓展。



一家之言，难免疏漏，望不吝斧正～
